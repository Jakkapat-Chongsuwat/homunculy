"""
PydanticAI LLM Service Implementation.

Provides infrastructure for interacting with Large Language Models using PydanticAI.
This is a concrete implementation of the domain LLMService interface.
"""

import os
from typing import Optional, Dict, Any

from pydantic_ai import Agent as PydanticAgent, ModelSettings
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider

from internal.domain.services import LLMService
from internal.domain.entities import AgentResponse, AgentConfiguration, AgentStatus


class PydanticAILLMService(LLMService):
    """
    PydanticAI-based LLM service implementation.
    
    Uses PydanticAI framework to interact with OpenAI models.
    This follows Clean Architecture by implementing the domain LLMService interface.
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize PydanticAI LLM service.
        
        Args:
            api_key: OpenAI API key (defaults to LLM_OPENAI_API_KEY env var)
        """
        self.api_key = api_key or os.getenv("LLM_OPENAI_API_KEY")
        
        if not self.api_key:
            raise ValueError("OpenAI API key not provided. Set LLM_OPENAI_API_KEY environment variable.")
    
    async def chat(
        self,
        configuration: AgentConfiguration,
        message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> AgentResponse:
        """
        Send a chat message using PydanticAI.
        
        Args:
            configuration: Agent configuration with model, temperature, etc.
            message: User message
            context: Optional conversation context
            
        Returns:
            AgentResponse with the LLM's reply
        """
        try:
            # Build system prompt with personality
            personality = configuration.personality
            system_prompt = configuration.system_prompt or ""
            
            # Add personality context
            personality_context = (
                f"You are {personality.name}. {personality.description}. "
                f"Your current mood is {personality.mood}."
            )
            
            full_system_prompt = f"{system_prompt}\n\n{personality_context}".strip()
            
            # Create OpenAI provider with API key
            provider = OpenAIProvider(api_key=self.api_key)
            
            # Create OpenAI chat model with provider and settings
            model = OpenAIChatModel(
                configuration.model_name,
                provider=provider
            )
            
            # Create agent with model and system prompt
            agent = PydanticAgent(
                model,
                system_prompt=full_system_prompt,
                model_settings=ModelSettings(
                    temperature=configuration.temperature,
                    max_tokens=configuration.max_tokens
                )
            )

            # Run the agent with user message (async)
            result = await agent.run(message)

            # Extract response from PydanticAI result
            # PydanticAI returns AgentRunResult with .output attribute
            response_text = result.output
            
            return AgentResponse(
                message=response_text,
                confidence=0.95,
                reasoning=f"Generated by {configuration.model_name} via PydanticAI",
                metadata={
                    "model": configuration.model_name,
                    "temperature": configuration.temperature,
                    "max_tokens": configuration.max_tokens,
                },
                status=AgentStatus.COMPLETED
            )
            
        except Exception as e:
            return AgentResponse(
                message=f"Error: {str(e)}",
                confidence=0.0,
                reasoning="Failed to communicate with LLM via PydanticAI",
                metadata={"error": str(e)},
                status=AgentStatus.ERROR
            )
